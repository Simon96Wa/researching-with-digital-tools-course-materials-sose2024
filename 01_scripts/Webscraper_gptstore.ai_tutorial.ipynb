{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gptstore.ai Daily Ranking scraper\n",
    "\n",
    "In der Sitzung am 4. Juni 2024 haben wir die beliebtesten GPTs an einem bestimmten Tag gescraped. Um mit diesem Scraper alle täglichen Rankings seit Februar 2024 zu erheben, könnte der Scraper um die Funktion erweitert werden, selsbtständig durch den Kalender zu navigieren. Alternativ können wir aber auch leicht die JSON Sitemap des scrapers so abwandeln, dass diese Funktion realsieiert wird. \n",
    "\n",
    "Letztlich ist ein mit dem Webscraper.io Browser Addon erzeugter Scraper nichts anderes als eine JSON Konfigurationsdatei. Diese können wir auch exportieren und adaptieren. Anstelle die Linkliste mit Python und Copilot zu erzeugen, könnten sie auch Google Sheets nutzen. \n",
    "\n",
    "**Hier die Schritt-für-Schritt Anleitung:**\n",
    "\n",
    "1.\tIn Webscraper.io können sie die Sitemap eines Scrapers unter ```Sitemap {SCRAPERNAME}/Export Sitemap``` exportieren. \n",
    "2.\tDie angezeigte Zeichenkette ist JSON und kann mit dem Script: ```Webscraper_Prettyfy_JSON.ipynb``` in eine gut formatierte JSON Datei gespeichert werden. \n",
    "    \n",
    "    a. Führen sie die erste  Zelle aus.\n",
    "    \n",
    "    b. Pasten sie den kopierten Sitemap-String in das kleine weiße Feld, das nach dem Ausführen erscheint. \n",
    "    \n",
    "    c.\tFühren sie die übrigen Zellen aus. \n",
    "    \n",
    "    (Das erneute Ausführen der ersten Zelle löscht den hineinkopierten Inhalt. Deshalb ist es wichtig nach dem Einfügen nur die übrigen Zellen auszuführen.)\n",
    "\n",
    "3.\tFühren Sie das Script ```Webscraper_gptstore.ai_generate_URL_list.ipynb``` aus und erstellen damit eine Liste von URLs, die unter ```Webscraper_gptstore.ai-daily-ranking-urls.txt```gespeichert wird.\n",
    "4.\tErsetzen Sie den Wert von ```startURL``` in der JSON-Datei des Scrapers mit der erstellten Liste.\n",
    "5.\tÄndern sie den Namen ihres Scrapers unter ```_id```, da jeder Webscraper einen eindeutigen Namen braucht.\n",
    "6.\tKopieren sie den Inhalt der JSON Datei und fügen diesen im Webscraper unter ```Create new sitemap/Import Sitemap``` ein.\n",
    "7.\tWählen Sie ihren neuen Webscraper aus.\n",
    "8.\tFühren Sie den Webscraper aus: ```Sitemap {SCRAPERNAME}/Scrape``` (Die Default Lade- und Wartezeiten können sie beibehalten.)\n",
    "9.\tLaden Sie die Daten unter ```Sitemap {SCRAPERNAME}/Export Data``` herunter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
